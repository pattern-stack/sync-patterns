# Future: Feature Generator

> Generate complete feature scaffolds from Pattern Stack model definitions

**Status**: Planning / Future capability

## Vision

Today sync-patterns generates typed API clients from OpenAPI specs. A natural extension is generating **backend feature scaffolds** from Pattern Stack model definitions.

The model with its `Pattern` config and `Field` definitions contains all the information needed to generate services and schemas deterministically.

## Motivation

From bi-patterns Phase 1a - 7 features following identical patterns:

```
features/
├── environments/    # ActorPattern
├── entities/        # CatalogPattern
├── dimensions/      # CatalogPattern
├── measures/        # CatalogPattern
├── metrics/         # CatalogPattern
├── data_models/     # CatalogPattern
└── sync_jobs/       # BasePattern
```

Each feature has:
- `models.py` - The source of truth (written by hand)
- `service.py` - Predictable from model (could be generated)
- `schemas/input.py` - Predictable from Field definitions (could be generated)
- `schemas/output.py` - Predictable from model + computed fields (could be generated)

Manual coding is:
- Repetitive (~300 lines per feature × 7 = 2100 lines)
- Error-prone (copy-paste mistakes)
- Drift-prone (model changes, forget to update schema)

## Proposed Command

```bash
# Generate feature scaffold from model
sync-patterns generate features app/backend/features/dimensions/models.py

# Generate for all models in a directory
sync-patterns generate features app/backend/features/*/models.py

# Watch mode - regenerate on model changes
sync-patterns generate features --watch app/backend/features/
```

## Input: Model Definition

```python
# features/dimensions/models.py

class DimensionType(str, Enum):
    CATEGORICAL = "categorical"
    TIME = "time"


class Dimension(CatalogPattern):
    """A dimension - grouping attribute for analysis."""

    __tablename__ = "dimensions"

    class Pattern:
        entity = "dimension"
        reference_prefix = "DIM"
        track_changes = True
        change_retention = "2555d"

    # Scoping
    environment_id: UUID = Field(UUID, required=True, index=True, foreign_key="environments.id")
    entity_id: UUID = Field(UUID, required=True, index=True, foreign_key="entities.id")

    # Identity
    name: str = Field(str, required=True, max_length=200, index=True)
    qualified_name: str = Field(str, required=True, max_length=400, index=True)
    label: str | None = Field(str, nullable=True, max_length=200)

    # Type
    dimension_type: str = Field(str, required=True, max_length=20, index=True)
    is_primary_time: bool = Field(bool, default=False, index=True)

    # Definition
    expr: str | None = Field(str, nullable=True, max_length=2000)
    granularities: list[str] = Field(list, default=list)

    # Tracking
    definition_hash: str | None = Field(str, nullable=True, max_length=64)

    # Meta
    meta: dict[str, Any] = Field(dict, default=dict)
```

## Output: Generated Files

### service.py

```python
# GENERATED by sync-patterns - DO NOT EDIT
# Source: features/dimensions/models.py

"""Service for Dimension operations."""

from uuid import UUID
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.backend.features.dimensions.models import Dimension
from app.backend.features.dimensions.schemas import DimensionCreate, DimensionUpdate
from pattern_stack.atoms.patterns.services import BaseService


class DimensionService(BaseService[Dimension, DimensionCreate, DimensionUpdate]):
    """Service for Dimension CRUD and queries."""

    model = Dimension

    # --- Generated from foreign_key="environments.id" ---
    async def list_for_environment(
        self, db: AsyncSession, environment_id: UUID
    ) -> list[Dimension]:
        query = (
            select(Dimension)
            .where(Dimension.environment_id == environment_id)
            .order_by(Dimension.created_at.desc())
        )
        result = await db.execute(query)
        return list(result.scalars().all())

    # --- Generated from foreign_key="entities.id" ---
    async def list_for_entity(
        self, db: AsyncSession, entity_id: UUID
    ) -> list[Dimension]:
        query = (
            select(Dimension)
            .where(Dimension.entity_id == entity_id)
            .order_by(Dimension.created_at.desc())
        )
        result = await db.execute(query)
        return list(result.scalars().all())

    # --- Generated from index=True on qualified_name ---
    async def get_by_qualified_name(
        self, db: AsyncSession, environment_id: UUID, qualified_name: str
    ) -> Dimension | None:
        query = select(Dimension).where(
            Dimension.environment_id == environment_id,
            Dimension.qualified_name == qualified_name,
        )
        result = await db.execute(query)
        return result.scalar_one_or_none()

    # --- Generated from unique constraint pattern ---
    async def upsert_by_qualified_name(
        self, db: AsyncSession, environment_id: UUID, data: DimensionCreate
    ) -> tuple[Dimension, bool]:
        existing = await self.get_by_qualified_name(db, environment_id, data.qualified_name)
        if existing:
            for field, value in data.model_dump(exclude_unset=True).items():
                setattr(existing, field, value)
            await db.commit()
            await db.refresh(existing)
            return existing, False
        else:
            entity = await self.create(db, data)
            return entity, True
```

### schemas/input.py

```python
# GENERATED by sync-patterns - DO NOT EDIT
# Source: features/dimensions/models.py

"""Input schemas for Dimension."""

from typing import Any
from uuid import UUID
from pydantic import BaseModel, Field


class DimensionCreate(BaseModel):
    """Create a new Dimension."""

    # Required fields (from Field(required=True))
    environment_id: UUID
    entity_id: UUID
    name: str = Field(..., max_length=200)
    qualified_name: str = Field(..., max_length=400)
    dimension_type: str = Field(..., max_length=20)

    # Optional fields (from Field(nullable=True) or Field(default=...))
    label: str | None = Field(default=None, max_length=200)
    is_primary_time: bool = Field(default=False)
    expr: str | None = Field(default=None, max_length=2000)
    granularities: list[str] = Field(default_factory=list)
    definition_hash: str | None = Field(default=None, max_length=64)
    meta: dict[str, Any] = Field(default_factory=dict)


class DimensionUpdate(BaseModel):
    """Update an existing Dimension."""

    # All fields optional for partial updates
    name: str | None = Field(default=None, max_length=200)
    qualified_name: str | None = Field(default=None, max_length=400)
    label: str | None = None
    dimension_type: str | None = Field(default=None, max_length=20)
    is_primary_time: bool | None = None
    expr: str | None = None
    granularities: list[str] | None = None
    definition_hash: str | None = None
    meta: dict[str, Any] | None = None
    is_active: bool | None = None  # From CatalogPattern
```

### schemas/output.py

```python
# GENERATED by sync-patterns - DO NOT EDIT
# Source: features/dimensions/models.py

"""Output schemas for Dimension."""

from datetime import datetime
from typing import Any
from uuid import UUID
from pydantic import BaseModel, ConfigDict


class DimensionResponse(BaseModel):
    """Dimension response for API."""

    model_config = ConfigDict(from_attributes=True)

    # Base fields (from BasePattern)
    id: UUID
    reference_number: str
    created_at: datetime
    updated_at: datetime | None

    # CatalogPattern fields
    is_active: bool

    # Model fields
    environment_id: UUID
    entity_id: UUID
    name: str
    qualified_name: str
    label: str | None
    dimension_type: str
    is_primary_time: bool
    expr: str | None
    granularities: list[str]
    definition_hash: str | None
    meta: dict[str, Any]
```

## Generation Rules

### From Pattern Base Class

| Pattern | Generated Service Methods |
|---------|--------------------------|
| `BasePattern` | Standard CRUD only |
| `CatalogPattern` | + `list_for_environment` (if environment_id exists) |
| `ActorPattern` | + `get_by_name` |
| `EventPattern` | + `transition_to`, state query methods |
| `RelationalPattern` | + relationship query methods |

### From Field Definitions

| Field Config | Generated |
|--------------|-----------|
| `foreign_key="X.id"` | `list_for_X(db, x_id)` method |
| `index=True` + unique pattern | `get_by_field(db, ...)` method |
| `required=True` | Required in CreateSchema |
| `nullable=True` | Optional in CreateSchema |
| `default=X` | Default value in CreateSchema |
| `max_length=N` | `Field(..., max_length=N)` in schema |

### From Composite Patterns

If model has both `environment_id` and another unique field like `qualified_name`:
- Generate `upsert_by_qualified_name(db, environment_id, data)` for sync operations

## Extension Points

### Custom Service Methods

For methods that can't be generated (domain logic), use a separate file:

```python
# features/dimensions/service_custom.py (hand-written)

from app.backend.features.dimensions.service import DimensionService as GeneratedService

class DimensionService(GeneratedService):
    """Extended service with custom methods."""

    async def list_time_dimensions(self, db, environment_id):
        """Custom: filter by dimension_type='time'."""
        ...
```

### Custom Schema Fields

For computed fields in output schemas:

```python
# features/dimensions/schemas/output_custom.py (hand-written)

from app.backend.features.dimensions.schemas.output import DimensionResponse as GeneratedResponse
from pydantic import computed_field

class DimensionResponse(GeneratedResponse):
    """Extended response with computed fields."""

    @computed_field
    @property
    def is_time(self) -> bool:
        return self.dimension_type == "time"
```

## Implementation Approach

1. **Parse model file** - Use Python AST to extract class definitions
2. **Extract Pattern config** - Identify base class, Pattern class attributes
3. **Extract Field definitions** - Parse Field() calls with all kwargs
4. **Apply generation rules** - Map patterns to templates
5. **Render templates** - Jinja2 templates for service.py, schemas/*.py
6. **Write files** - With "GENERATED - DO NOT EDIT" header

## Open Questions

1. **Regeneration strategy** - Overwrite always? Merge? Separate generated/custom files?

2. **Validation** - Should we validate that generated code compiles/type-checks?

3. **Migration generation** - Should this also generate Alembic migrations?

4. **Enum handling** - How to handle Enum definitions in models.py?

5. **Relationship loading** - Should generated services include eager loading options?

## Related

- `bi-patterns/specs/phase-1-features.md` - The use case that inspired this
- `backend-patterns/` - Pattern base classes and Field abstraction
- `sync-patterns/` - Current generator infrastructure to build on
